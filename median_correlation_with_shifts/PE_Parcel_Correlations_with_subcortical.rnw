\documentclass[letterpaper]{article}
\usepackage{fullpage}
\addtolength{\hoffset}{-.5in}
\addtolength{\textwidth}{1in}
\addtolength{\voffset}{-.5in}
\addtolength{\textheight}{1in}
\begin{document}


<<startup, echo=FALSE, message=FALSE>>=
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=100), options(width=80))
# DCL e152 piloting. started 4 October 2022 by Jo Etzel
# fixed movie stat input files, 10 October 2022

library(RNifti)
library(stringr)
rm(list = ls())
# safety option
options(warnPartialMatchDollar = TRUE)

# root directory
in.path <- "/data/nil-external/dcl/Events152_fMRI_NeuralMechanisms/voxelwiseAnalyses/"

sub.ids <- c(paste0("0", 1:9), 10:47);
run.ids <- 1:4;
nframes <- c(405, 467, 404, 444);  # number of frames in each run, run.ids order
movie.ids <- c("1.2.3_C1_trim", "6.3.9_C1_trim", "3.1.3_C1_trim", "2.4.1_C1_trim");  # clip names in run.ids order; see analysisPrep.R
mov.ids <- c("1.2.3", "6.3.9", "3.1.3", "2.4.1");  # clip names in run.ids order; see analysisPrep.R
# directory for PE feature files
feature_dir <- paste0(in.path, "knitr_tan/median_correlation_with_shifts/PECorrs_1_150/")
# check if feature_dir exists
if (!file.exists(feature_dir)) {
  dir.create(feature_dir)
}




suff_sch <- "np2_Sch400x7";  # last bit of the input filenames
suff_subcortical <- "np2_subcortical";  # last bit of the input filenames
TR <- 1.483;   # TR in seconds
#do.trim <- 0.1;
get.FTrz <- function(in.val) {
  return(.5 * log((1 + in.val) / (1 - in.val)))
} # Fisher's r-to-z transformation.
get.FTzr <- function(in.val) {
  return((exp(2 * in.val) - 1) / (exp(2 * in.val) + 1))
} # Fisher's z-to-r transformation

source("/data/nil-external/ccp/JosetAEtzel/DMCC_files/niftiPlottingFunctions.R");

under.img <- readNifti(paste0(in.path, "HCP_S1200T1w_94x111x94.nii.gz")); # made in analysisPrep.R
sch.img <- readNifti(paste0(in.path, "Schaefer2018_400x7_94x111x94.nii.gz"));
sub.img <- readNifti(paste0(in.path, "subcortical_94x111x94.nii.gz"));
subcort.tbl <- read.csv(paste0(in.path, "subcorticalKey.csv"), stringsAsFactors=FALSE);  # subcortical_94x111x94.nii.gz parcel labels

sch.ids <- 1:400;   # Schaefer2018_400x7 parcellation

# # Schaefer parcellation labels for each parcel, useful for plotting
# # this file is fetched from github.
# fname <- paste0(in.path, "knitr_tan/median_correlation_with_shifts/Schaefer2018_400Parcels_7Networks_order_info.txt")
# if (file.exists(fname)) {
#   fin <- file(fname, "rt")
#   tmp <- readLines(fin)
#   close(fin)
#   unlink(fin)
#   if (length(tmp) != 800) {
#     stop("not expected Schaefer key.")
#   }
#   tmp <- tmp[seq(from = 1, to = 800, by = 2)] # every-other entry is a label
#   p.key <- gsub("7Networks_", "", tmp)
# } else {
#   print(paste("Not exist", fname))
# }
# # extract out the network part of each parcel name
# tmp <- strsplit(p.key, "_");
# network.key <- rep(NA, length(p.key));
# for (i in 1:length(p.key)) {
#   network.key[i] <- tmp[[i]][2]
# }
# # length(unique(network.key))    # [1] 7
# network.ids <- unique(network.key)
# # length(network.ids)  # [1] 400
# # export to a txt file, easier for other plotting code to use
# write.table(network.key, paste0(in.path, "knitr_tan/median_correlation_with_shifts/network_key_Schaefer_400Parcels.txt"), row.names = FALSE, col.names = FALSE)

plot.slices <- round(seq(from=27, to=72, length.out=10));   # slices to show


onset.tbl <- read.table(paste0(in.path, "e152onsets.txt"));  # delay between first TR and movie onset, in sec
#  head(onset.tbl)
#   sub.id sub.lbl run1_1.2.3 run2_6.3.9 run3_3.1.3 run4_2.4.1
# 1 sub-01 e152003   7.900409   8.328984   7.929364   8.195244
# 2 sub-02 e152004   8.856364   8.909626   8.313563   8.564747
pe.onsets <- c(6.16, 7.88, 5.52, 6.82) # in seconds, the delay between movie onset and PE onset.

# column names and order of the movie-stat input files
#mstat.ids <- c("time", "pixel_change_mean", "pixel_change_var" , "luminance_mean", "luminance_var");


nlims <- c(-0.2, -0.05)
plims <- c(0.05, 0.2)   # used in the brain-plotting code, too.

# This function load the parcel-avg and pe correlation (created by corr.parcel.pe) and plot correlation for each subject.
just.plot.subject <- function(do.col, do.start, rid, sid) {
  # do.col <- "pe"; do.start <- 0; rid <- 1; sid <- 1
  # print(paste(do.col, " run", movie.ids[rid], "at various starts (starts in TR)"));
  temp.img <- array(0, dim(under.img))
  for (do.par in c("Schaefer2018_400x7", "subcortical")) {
    # specify parcel ids, parcel-pe correlations, and "under" img to plot (Schaefer or subcortical)
    if (do.par == "Schaefer2018_400x7") {
      p.lbls <- sch.ids # 1:400
      p.img <- sch.img
      fname <- paste0(feature_dir, "matlabCorrs_", do.col, "_run", rid, "_dtFixed.txt")
      # print(paste("Loading", fname));
      cor.tbl <- read.table(fname)
    }
    if (do.par == "subcortical") {
      p.lbls <- subcort.tbl$HCP.label
      p.img <- sub.img
      fname <- paste0(feature_dir, "matlabCorrs_", do.col, "_run", rid, "_dtFixed_subcortical.txt")
      cor.tbl <- read.table(fname)
    }
    # use column name since parcel order not fixed for subcortical
    # for (pid in 1:length(p.lbls)) {
    for (pid in p.lbls) {
      # vals <- cor.tbl[which(cor.tbl$start.at == paste0("corrAt", do.start)),paste0("p", pid)];
      # temp.img[which(p.img == pid)] <- median(vals);
      # sid_str <- "01";
      sid_str <- str_pad(sid, width = 2, pad = "0")
      val <- cor.tbl[which((cor.tbl$start.at == paste0("corrAt", do.start)) & (cor.tbl$sub.id == paste0("sub-", sid_str))), paste0("p", pid)]
      temp.img[which(p.img == pid)] <- val
    }
  }
  plot.volume(temp.img, under.img, neg.lims = nlims, pos.lims = plims, ttl = paste0(do.start, movie.ids[rid], " ", do.col))
}

# This function load the parcel-avg and pe correlation (created by corr.parcel.pe) and plot median correlation across subjects.
just.plot.median <- function(do.col, do.start, rid) {   # do.col <- "pe"; do.start <- 0; rid <- 1;
    # print(paste(do.col, " run", movie.ids[rid], "at various starts (starts in TR)"));
    temp.img <- array(0, dim(under.img));
    for (do.par in c("Schaefer2018_400x7", "subcortical")) {
      if (do.par == "Schaefer2018_400x7") {
        p.lbls <- sch.ids; # 1:400
        p.img <- sch.img;
  # do.start <- 0; rid <- 1; do.col <- "pixel_change_mean";
  # made above; do.start must be in the .txt
        fname <- paste0(in.path, "knitr_tan/median_correlation_with_shifts/PECorrs/matlabCorrs_", do.col, "_run", rid, "_dtFixed.txt");
        # print(paste("Loading", fname));
        cor.tbl <- read.table(fname);
      }
      if (do.par == "subcortical") {
        p.lbls <- subcort.tbl$HCP.label
        p.img <- sub.img;
        # do.start <- 0; rid <- 1; do.col <- "pixel_change_mean";
        # made above; do.start must be in the .txt
        fname <- paste0(in.path, "knitr_tan/median_correlation_with_shifts/PECorrs/matlabCorrs_", do.col, "_run", rid, "_dtFixed_subcortical.txt")
        cor.tbl <- read.table(fname)
      }
              # use column name since parcel order not fixed for subcortical
      # for (pid in 1:length(p.lbls)) {
      for (pid in p.lbls) {
        vals <- cor.tbl[which(cor.tbl$start.at == paste0("corrAt", do.start)), paste0("p", pid)];
        temp.img[which(p.img == pid)] <- median(vals);
      }
    }
  plot.volume(temp.img, under.img, neg.lims=nlims, pos.lims=plims, ttl=paste0(do.start, movie.ids[rid], " ", do.col));
}


# This function load parcel-average timeseries for each subject, shift them and correlate it with PE timeseries.
# All correlations are saved in a single .txt file
corr.parcel.pe <- function(do.col, do.starts, rid, from, to) {
  # do.starts <- 0:1; rid <- 1; do.col <- "pe";   # which column of the movie-stat file to correlate the BOLD against, rid is movie id.
  # from <- 1; to <- 100;   # the duration of the movie in TRs to correlate the BOLD against.
  for (do.par in c("Schaefer2018_400x7", "subcortical")) {
    if (do.par == "Schaefer2018_400x7") {
      fname.out <- paste0(feature_dir, "matlabCorrs_", do.col, "_run", rid, "_dtFixed.txt")
      p.lbls <- sch.ids
      suff <- suff_sch
    }
    if (do.par == "subcortical") {
      fname.out <- paste0(feature_dir, "matlabCorrs_", do.col, "_run", rid, "_dtFixed_subcortical.txt")
      p.lbls <- subcort.tbl$HCP.label
      suff <- suff_subcortical
    }
    # fname.out <- paste0(in.path, "knitr_tan/median_correlation_with_shifts/PECorrs/matlabCorrs_", do.col, "_run", rid, "_dtFixed.txt");
    if (!file.exists(fname.out)) { # correlate parcel timeseries of all subjects with PE and save
      # load in the parcel-average timeseries of all subjects for each run & store so don't need to read over and over
      nps.lst <- vector("list", length(sub.ids))
      for (sid in 1:length(sub.ids)) { # sid <- 1;
        # path to parcel-average timeseries of this subject
        fname <- paste0(in.path, "np2/sub-", sub.ids[sid], "_run-", rid, "_", suff, ".txt")
        if (file.exists(fname)) {
          np.tbl <- read.delim(fname)
          np.tbl <- np.tbl[, -c(1, 2)] # take off first two label columns
          if (nrow(np.tbl) != nframes[rid] | ncol(np.tbl) != length(p.lbls)) {
            print(paste(nrow(np.tbl), nframes[rid], ncol(np.tbl), length(p.lbls)))
            stop("wrong np.tbl.")
          }
          sub.onset <- onset.tbl[which(onset.tbl$sub.id == paste0("sub-", sub.ids[sid])), paste0("run", rid, "_", mov.ids[rid])] # onset in seconds
          pe.onset <- pe.onsets[rid]
          total_onset <- sub.onset + pe.onset
          TR.onset <- round(total_onset / TR) # onset in TR, combining subject (scanning started before movie onset) and pe onset (pe starts not at movie onset but later).

          nps.lst[[sid]] <- np.tbl[(TR.onset:nrow(np.tbl)), ] # keep frames, starting at movie + PE start
        } else {
          stop("missing???")
        }
      }
      rm(np.tbl, fname) # cleanup

      # load convoluted PE for this movie, used for all people
      pe.vec <- read.csv(paste0(in.path, "matlab_resampling2/out_convo_pe/conv_", mov.ids[rid], "_", do.col, "_dtFix.csv"), header = FALSE)
      pe.vec <- unlist(pe.vec[1, ], use.names = FALSE)

      # one output file, set of starts
      # trim 5-10 points off the front of the movie timeseries to avoid the starting big-dip????
      out.tbl <- data.frame(array(NA, c(length(sub.ids) * length(do.starts), length(p.lbls) + 2)))
      # column names are parcel numbers
      colnames(out.tbl) <- c("sub.id", "start.at", paste0("p", p.lbls))
      ctr <- 1 # counter = #subs * #starts
      for (sid in 1:length(sub.ids)) { # sid <- 2;
        # already trimmed pre-onset frames from the parcel-average timeseries
        # sub.onset <- onset.tbl[which(onset.tbl$sub.id == paste0("sub-", sub.ids[sid])), paste0("run", rid, "_", movie.ids[rid])];

        for (do.start in do.starts) { #  sid <- 2;  do.start <- 0;
          pe.vec2 <- pe.vec # reset
          pe.vec2 <- pe.vec2[from:min(to, nrow(pe.vec2))] # trim off the movie
          do.TRs <- (1 + do.start + from - 1):nrow(nps.lst[[sid]]) # frames in this run, starting at do.start
          if (length(do.TRs) < length(pe.vec2)) {
            pe.vec2 <- pe.vec2[1:length(do.TRs)]
          } # trim end of movie so vectors match length
          if (length(pe.vec2) < length(do.TRs)) {
            do.TRs <- do.TRs[1:length(pe.vec2)]
          }
          out.tbl$sub.id[ctr] <- paste0("sub-", sub.ids[sid])
          out.tbl$start.at[ctr] <- paste0("corrAt", do.start)
          for (pid in 1:length(p.lbls)) {
            out.tbl[ctr, pid + 2] <- cor(nps.lst[[sid]][do.TRs, pid], pe.vec2, method = "pearson")
          }
          ctr <- ctr + 1
        }
      }
      print(paste("Saving", fname.out))
      write.table(out.tbl, fname.out)
    } else {
      print(paste("Existed, skip:", fname.out))
    }
  }
  # for (do.start in do.starts) {
  #   just.plot(do.col, do.start, rid)
  # }
}


@

\noindent compiled \today\  \par
\noindent DCL events152 positive controls, with matlab convolution and downsampling. \par
\noindent files under \texttt{/data/nil-external/dcl/Events152\textunderscore fMRI\textunderscore NeuralMechanisms/voxelwiseAnalyses/} \par
\vspace{0.2 cm} 
\noindent 47 people watched movies in four fMRI runs; everyone watched the same movie in each run (four different movies total; same order for everyone). Images were preprocessed with fmriprep (volumes only), then np2 detrended and normalized, and finally parcel-averaged using the Schaefer2018 400x7 parcellation (\texttt{analysisPrep.R}). The runs had the same number of volumes for everyone but the movie onsets varied a bit (7.9 to 11.4 seconds); see \texttt{e152onsets.txt} and \texttt{getOnsets.R}. \par
\vspace{0.2 cm}
\noindent The correlations here follow the same logic as \texttt{/knitr/parcelCorrelations/movieParcelCorrelations.rnw}, but with Matt's matlab code for convolving and downsampling the framewise movie measures, \texttt{/matlab\textunderscore resampling/Bezdek\textunderscore resampling.m}. Tan Nguyen created the files with PE statistic experienced by SEM model for each frame of each movie. These stats are every 0.333 seconds, much faster than the BOLD or the TR (1.483 sec). \par
\vspace{0.2 cm}
\noindent Aligning the movie and BOLD timeseries properly before correlating has been a challenge, but seems to be sorted now. The first section gives shows the median correlation for each movie statistic and run at offset 0, which should be (and is) best. A selection of the other offsets are shown on later pages, and it's clear the correlation gets worse as the offset increases.   \par




\newpage
\noindent pe  \par
\vspace{0.2 cm} 
<<code2legend, echo=FALSE, dev='pdf', fig.height=0.3, fig.width=7.5, fig.align="center">>=
par(oma = rep(0.2, 4), mar = rep(0, 4), mgp = rep(0, 3))

#nlims <- c(-0.2,-0.05); plims <- c(0.05, 0.2);   # used in the brain-plotting code, too.

# blank plot
plot(x = 0, y = 0, xlim = c(-10, 131), type = "n", ylab = "", xlab = "", main = "", bty = "n", xaxt = "n", yaxt = "n")
for (i in 1:length(cols.warm)) {
  rect(xleft = 66 + i, xright = 67 + i, ybottom = -0.5, ytop = 0.5, col = cols.warm[i], border = cols.warm[i])
}
for (i in 1:length(cols.cool)) {
  rect(xleft = 53 - i, xright = 54 - i, ybottom = -0.5, ytop = 0.5, col = cols.cool[i], border = cols.cool[i])
}
text(x=-8, y=0, labels=nlims[1], adj=1, cex=0.7);   # adj=1 for right-justified text; adj=0 for left-justified
text(x=53.5, y=0, labels=nlims[2], adj=0, cex=0.7);
#text(x=60, y=0, labels=0, cex=0.8);
text(x=66, y=0, labels=plims[1], adj=1, cex=0.7);
text(x=128, y=0, labels=plims[2], adj=0, cex=0.7);

@
\vspace{0.2 cm}
<<code2, dev='pdf', cache=TRUE, echo=FALSE, fig.height=1, fig.width=8, fig.align='center'>>=

#for (i in 1:4) { just.plot("pixel_change_mean", 0, i); }
for (i in 1:4) {
  print(paste("calculate correlations for run", movie.ids[i], "at various starts (starts in TR)"));
  corr.parcel.pe("pe", 0:5, i, 1, 150)
}

@

\newpage
\noindent pe  \par
\vspace{0.4 cm}

<<code4legend, echo=FALSE, dev='pdf', fig.height=0.3, fig.width=7.5, fig.align="center">>=
par(oma = rep(0.2, 4), mar = rep(0, 4), mgp = rep(0, 3))

# blank plot
plot(x = 0, y = 0, xlim = c(-10, 131), type = "n", ylab = "", xlab = "", main = "", bty = "n", xaxt = "n", yaxt = "n")
for (i in 1:length(cols.warm)) {
  rect(xleft = 66 + i, xright = 67 + i, ybottom = -0.5, ytop = 0.5, col = cols.warm[i], border = cols.warm[i])
}
for (i in 1:length(cols.cool)) {
  rect(xleft = 53 - i, xright = 54 - i, ybottom = -0.5, ytop = 0.5, col = cols.cool[i], border = cols.cool[i])
}
text(x=-8, y=0, labels=nlims[1], adj=1, cex=0.7)   # adj=1 for right-justified text; adj=0 for left-justified
text(x=53.5, y=0, labels=nlims[2], adj=0, cex=0.7)
#text(x=60, y=0, labels=0, cex=0.8);
text(x=66, y=0, labels=plims[1], adj=1, cex=0.7)
text(x=128, y=0, labels=plims[2], adj=0, cex=0.7)

@
\vspace{0.2 cm}
<<code4, dev='pdf', cache=TRUE, echo=FALSE, fig.height=1, fig.width=8, fig.align='center', results='asis'>>=
# <<code4, dev='pdf', cache=TRUE, echo=FALSE, fig.height=1, fig.width=8, fig.align='center'>>=


# grouping by subject
# for (do.col in c("pe")) {
#   print(paste(do.col, "stats"));
#   for (sid in 1:47) {
#     for (i in 1:4) {
#       print(paste("subject", sid, "run", mov.ids[i], do.col, "stats"), quote=FALSE);
#       just.plot.subject(do.col, 0, i, sid);
#     }
#     cat("\n\\newpage\n");
#   }
# }

# grouping by movie
for (do.col in c("pe")) {
  print(paste(do.col, "stats"));
  for (i in 1:4) {
    for (sid in 1:47) {
      print(paste("subject", sid, "run", mov.ids[i], do.col, "stats"), quote=FALSE);
      just.plot.subject(do.col, 0, i, sid);
    }
    cat("\n\\newpage\n");
  }
}
@


\end{document}